{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "sourceId": 7983606,
     "sourceType": "datasetVersion",
     "datasetId": 4699265
    }
   ],
   "dockerImageVersionId": 30674,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from skimage import io\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MinMaxScaler\n",
    "from scipy.sparse import csr_matrix\n"
   ],
   "metadata": {
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "execution": {
     "iopub.status.busy": "2024-03-30T16:11:27.245492Z",
     "iopub.execute_input": "2024-03-30T16:11:27.246777Z",
     "iopub.status.idle": "2024-03-30T16:11:52.305310Z",
     "shell.execute_reply.started": "2024-03-30T16:11:27.246727Z",
     "shell.execute_reply": "2024-03-30T16:11:52.304275Z"
    },
    "trusted": true
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "text": "2024-03-30 16:11:30.901900: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-30 16:11:30.902019: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-30 16:11:31.221092: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "api_key = {\n",
    "'username':\"floreageorge\" ,\n",
    "'key':\"c392f1958292932eb60951c0fa720f33\"}\n",
    "\n",
    "kaggle_path = Path('/root/.kaggle')\n",
    "os.makedirs(kaggle_path, exist_ok=True)\n",
    "\n",
    "with open (kaggle_path/'kaggle.json', 'w') as handl:\n",
    "    json.dump(api_key,handl)\n",
    "\n",
    "os.chmod(kaggle_path/'kaggle.json', 600)\n",
    "\n",
    "!kaggle competitions download -c nitro-nlp-3\n",
    "!unzip nitro-nlp-3.zip"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:12:02.858001Z",
     "iopub.execute_input": "2024-03-30T16:12:02.858750Z",
     "iopub.status.idle": "2024-03-30T16:12:09.831260Z",
     "shell.execute_reply.started": "2024-03-30T16:12:02.858716Z",
     "shell.execute_reply": "2024-03-30T16:12:09.830020Z"
    },
    "trusted": true
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": "Downloading nitro-nlp-3.zip to /kaggle/working\n 97%|████████████████████████████████████▉ | 79.0M/81.4M [00:01<00:00, 56.5MB/s]\n100%|██████████████████████████████████████| 81.4M/81.4M [00:01<00:00, 50.7MB/s]\nArchive:  nitro-nlp-3.zip\n  inflating: random_seed_setter.py   \n  inflating: sample_test_solution.csv  \n  inflating: test.csv                \n  inflating: train.csv               \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test =  pd.read_csv('test.csv')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:12:09.833750Z",
     "iopub.execute_input": "2024-03-30T16:12:09.834154Z",
     "iopub.status.idle": "2024-03-30T16:12:13.865602Z",
     "shell.execute_reply.started": "2024-03-30T16:12:09.834118Z",
     "shell.execute_reply": "2024-03-30T16:12:13.864682Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train['title'] = train['title'].str.lower()\n",
    "train['content'] = train['content'].str.lower()\n",
    "train['labels'] = train['class'].astype(int)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:12:13.866867Z",
     "iopub.execute_input": "2024-03-30T16:12:13.867281Z",
     "iopub.status.idle": "2024-03-30T16:12:15.785645Z",
     "shell.execute_reply.started": "2024-03-30T16:12:13.867246Z",
     "shell.execute_reply": "2024-03-30T16:12:15.784495Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download ro_core_news_sm"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:12:15.788001Z",
     "iopub.execute_input": "2024-03-30T16:12:15.788418Z",
     "iopub.status.idle": "2024-03-30T16:12:59.205979Z",
     "shell.execute_reply.started": "2024-03-30T16:12:15.788382Z",
     "shell.execute_reply": "2024-03-30T16:12:59.204739Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "Requirement already satisfied: spacy in /opt/conda/lib/python3.10/site-packages (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy) (2.1.3)\nCollecting ro-core-news-sm==3.7.0\n  Downloading https://github.com/explosion/spacy-models/releases/download/ro_core_news_sm-3.7.0/ro_core_news_sm-3.7.0-py3-none-any.whl (12.9 MB)\n\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m12.9/12.9 MB\u001B[0m \u001B[31m71.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\n\u001B[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from ro-core-news-sm==3.7.0) (3.7.2)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (1.0.10)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.0.8)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (8.2.2)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (1.1.2)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.4.8)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.0.10)\nRequirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (0.3.4)\nRequirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (0.9.0)\nRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (6.4.0)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (4.66.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.31.0)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.5.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.1.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (69.0.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (21.3)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.3.0)\nRequirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (1.26.4)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.1.1)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.14.6)\nRequirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (4.9.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2024.2.2)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (0.7.10)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (0.1.4)\nRequirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (8.1.7)\nRequirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (0.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->ro-core-news-sm==3.7.0) (2.1.3)\nInstalling collected packages: ro-core-news-sm\nSuccessfully installed ro-core-news-sm-3.7.0\n\u001B[38;5;2m✔ Download and installation successful\u001B[0m\nYou can now load the package via spacy.load('ro_core_news_sm')\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "from spacy.lang.ro.stop_words import STOP_WORDS\n",
    "\n",
    "nlp = spacy.load(\"ro_core_news_sm\", disable=[\"parser\", \"ner\"])\n",
    "\n",
    "def preprocess_texts(texts):\n",
    "    texts = [str(text) if pd.notnull(text) else '' for text in texts]\n",
    "\n",
    "    docs = nlp.pipe(texts, batch_size=50)\n",
    "    preprocessed_texts = []\n",
    "    for doc in docs:\n",
    "        preprocessed_text = ' '.join(token.lemma_ for token in doc if not token.is_stop and not token.is_punct and token.lemma_ != \"-PRON-\")\n",
    "        preprocessed_texts.append(preprocessed_text)\n",
    "    return preprocessed_texts\n",
    "\n",
    "\n",
    "train['title_processed'] = preprocess_texts(train['title'].tolist())\n",
    "train['content_processed'] = preprocess_texts(train['content'].tolist())\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:12:59.207894Z",
     "iopub.execute_input": "2024-03-30T16:12:59.208394Z",
     "iopub.status.idle": "2024-03-30T16:13:57.596755Z",
     "shell.execute_reply.started": "2024-03-30T16:12:59.208348Z",
     "shell.execute_reply": "2024-03-30T16:13:57.594674Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 6,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 17\u001B[0m\n\u001B[1;32m     13\u001B[0m         preprocessed_texts\u001B[38;5;241m.\u001B[39mappend(preprocessed_text)\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m preprocessed_texts\n\u001B[0;32m---> 17\u001B[0m train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtitle_processed\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mpreprocess_texts\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtitle\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtolist\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent_processed\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m preprocess_texts(train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist())\n",
      "Cell \u001B[0;32mIn[6], line 11\u001B[0m, in \u001B[0;36mpreprocess_texts\u001B[0;34m(texts)\u001B[0m\n\u001B[1;32m      9\u001B[0m docs \u001B[38;5;241m=\u001B[39m nlp\u001B[38;5;241m.\u001B[39mpipe(texts, batch_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m50\u001B[39m)\n\u001B[1;32m     10\u001B[0m preprocessed_texts \u001B[38;5;241m=\u001B[39m []\n\u001B[0;32m---> 11\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs:\n\u001B[1;32m     12\u001B[0m     preprocessed_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(token\u001B[38;5;241m.\u001B[39mlemma_ \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m doc \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m token\u001B[38;5;241m.\u001B[39mis_stop \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m token\u001B[38;5;241m.\u001B[39mis_punct \u001B[38;5;129;01mand\u001B[39;00m token\u001B[38;5;241m.\u001B[39mlemma_ \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m-PRON-\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     13\u001B[0m     preprocessed_texts\u001B[38;5;241m.\u001B[39mappend(preprocessed_text)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/language.py:1618\u001B[0m, in \u001B[0;36mLanguage.pipe\u001B[0;34m(self, texts, as_tuples, batch_size, disable, component_cfg, n_process)\u001B[0m\n\u001B[1;32m   1616\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m pipe \u001B[38;5;129;01min\u001B[39;00m pipes:\n\u001B[1;32m   1617\u001B[0m         docs \u001B[38;5;241m=\u001B[39m pipe(docs)\n\u001B[0;32m-> 1618\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs:\n\u001B[1;32m   1619\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m doc\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:1685\u001B[0m, in \u001B[0;36m_pipe\u001B[0;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pipe\u001B[39m(\n\u001B[1;32m   1676\u001B[0m     docs: Iterable[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   1677\u001B[0m     proc: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeCallable\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     kwargs: Mapping[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m   1683\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1684\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipe\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1685\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mpipe(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1687\u001B[0m         \u001B[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001B[39;00m\n\u001B[1;32m   1688\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(kwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/pipe.pyx:55\u001B[0m, in \u001B[0;36mpipe\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:1685\u001B[0m, in \u001B[0;36m_pipe\u001B[0;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pipe\u001B[39m(\n\u001B[1;32m   1676\u001B[0m     docs: Iterable[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   1677\u001B[0m     proc: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeCallable\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     kwargs: Mapping[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m   1683\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1684\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipe\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1685\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mpipe(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1687\u001B[0m         \u001B[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001B[39;00m\n\u001B[1;32m   1688\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(kwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001B[0m, in \u001B[0;36mpipe\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:1632\u001B[0m, in \u001B[0;36mminibatch\u001B[0;34m(items, size)\u001B[0m\n\u001B[1;32m   1630\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m   1631\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(size_)\n\u001B[0;32m-> 1632\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mitertools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mislice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1633\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(batch) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1634\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:1685\u001B[0m, in \u001B[0;36m_pipe\u001B[0;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pipe\u001B[39m(\n\u001B[1;32m   1676\u001B[0m     docs: Iterable[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   1677\u001B[0m     proc: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeCallable\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     kwargs: Mapping[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m   1683\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1684\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipe\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1685\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mpipe(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1687\u001B[0m         \u001B[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001B[39;00m\n\u001B[1;32m   1688\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(kwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:73\u001B[0m, in \u001B[0;36mpipe\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:1632\u001B[0m, in \u001B[0;36mminibatch\u001B[0;34m(items, size)\u001B[0m\n\u001B[1;32m   1630\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m   1631\u001B[0m     batch_size \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(size_)\n\u001B[0;32m-> 1632\u001B[0m     batch \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mitertools\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mislice\u001B[49m\u001B[43m(\u001B[49m\u001B[43mitems\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1633\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(batch) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1634\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/util.py:1685\u001B[0m, in \u001B[0;36m_pipe\u001B[0;34m(docs, proc, name, default_error_handler, kwargs)\u001B[0m\n\u001B[1;32m   1675\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_pipe\u001B[39m(\n\u001B[1;32m   1676\u001B[0m     docs: Iterable[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m],\n\u001B[1;32m   1677\u001B[0m     proc: \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mPipeCallable\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1682\u001B[0m     kwargs: Mapping[\u001B[38;5;28mstr\u001B[39m, Any],\n\u001B[1;32m   1683\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Iterator[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDoc\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m   1684\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(proc, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpipe\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m-> 1685\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m proc\u001B[38;5;241m.\u001B[39mpipe(docs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m   1686\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1687\u001B[0m         \u001B[38;5;66;03m# We added some args for pipe that __call__ doesn't expect.\u001B[39;00m\n\u001B[1;32m   1688\u001B[0m         kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mdict\u001B[39m(kwargs)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/trainable_pipe.pyx:75\u001B[0m, in \u001B[0;36mpipe\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/spacy/pipeline/tok2vec.py:126\u001B[0m, in \u001B[0;36mTok2Vec.predict\u001B[0;34m(self, docs)\u001B[0m\n\u001B[1;32m    124\u001B[0m     width \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mget_dim(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnO\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    125\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39malloc((\u001B[38;5;241m0\u001B[39m, width)) \u001B[38;5;28;01mfor\u001B[39;00m doc \u001B[38;5;129;01min\u001B[39;00m docs]\n\u001B[0;32m--> 126\u001B[0m tokvecs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdocs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m tokvecs\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:334\u001B[0m, in \u001B[0;36mModel.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    330\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m OutT:\n\u001B[1;32m    331\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function with `is_train=False`, and return\u001B[39;00m\n\u001B[1;32m    332\u001B[0m \u001B[38;5;124;03m    only the output, instead of the `(output, callback)` tuple.\u001B[39;00m\n\u001B[1;32m    333\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 334\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m[\u001B[38;5;241m0\u001B[39m]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/with_array.py:42\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, Xseq, is_train)\u001B[0m\n\u001B[1;32m     40\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers[\u001B[38;5;241m0\u001B[39m](Xseq, is_train)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m---> 42\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m cast(Tuple[SeqT, Callable], \u001B[43m_list_forward\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mXseq\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/with_array.py:77\u001B[0m, in \u001B[0;36m_list_forward\u001B[0;34m(model, Xs, is_train)\u001B[0m\n\u001B[1;32m     75\u001B[0m lengths \u001B[38;5;241m=\u001B[39m NUMPY_OPS\u001B[38;5;241m.\u001B[39masarray1i([\u001B[38;5;28mlen\u001B[39m(seq) \u001B[38;5;28;01mfor\u001B[39;00m seq \u001B[38;5;129;01min\u001B[39;00m Xs])\n\u001B[1;32m     76\u001B[0m Xf \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mflatten(Xs, pad\u001B[38;5;241m=\u001B[39mpad)\n\u001B[0;32m---> 77\u001B[0m Yf, get_dXf \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mXf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mbackprop\u001B[39m(dYs: ListXd) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m ListXd:\n\u001B[1;32m     80\u001B[0m     dYf \u001B[38;5;241m=\u001B[39m layer\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mflatten(dYs, pad\u001B[38;5;241m=\u001B[39mpad)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/residual.py:41\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     39\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m d_output \u001B[38;5;241m+\u001B[39m dX\n\u001B[0;32m---> 41\u001B[0m Y, backprop_layer \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlayers\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, \u001B[38;5;28mlist\u001B[39m):\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [X[i] \u001B[38;5;241m+\u001B[39m Y[i] \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mlen\u001B[39m(X))], backprop\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "    \u001B[0;31m[... skipping similar frames: Model.__call__ at line 310 (1 times)]\u001B[0m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/chain.py:54\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     52\u001B[0m callbacks \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m     53\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m layer \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mlayers:\n\u001B[0;32m---> 54\u001B[0m     Y, inc_layer_grad \u001B[38;5;241m=\u001B[39m \u001B[43mlayer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mappend(inc_layer_grad)\n\u001B[1;32m     56\u001B[0m     X \u001B[38;5;241m=\u001B[39m Y\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/model.py:310\u001B[0m, in \u001B[0;36mModel.__call__\u001B[0;34m(self, X, is_train)\u001B[0m\n\u001B[1;32m    307\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, X: InT, is_train: \u001B[38;5;28mbool\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tuple[OutT, Callable]:\n\u001B[1;32m    308\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Call the model's `forward` function, returning the output and a\u001B[39;00m\n\u001B[1;32m    309\u001B[0m \u001B[38;5;124;03m    callback to compute the gradients via backpropagation.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 310\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_func\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mis_train\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/thinc/layers/maxout.py:52\u001B[0m, in \u001B[0;36mforward\u001B[0;34m(model, X, is_train)\u001B[0m\n\u001B[1;32m     50\u001B[0m W \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mget_param(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mW\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     51\u001B[0m W \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape2f(W, nO \u001B[38;5;241m*\u001B[39m nP, nI)\n\u001B[0;32m---> 52\u001B[0m Y \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgemm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mW\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrans2\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m     53\u001B[0m Y \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape1f(b, nO \u001B[38;5;241m*\u001B[39m nP)\n\u001B[1;32m     54\u001B[0m Z \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mops\u001B[38;5;241m.\u001B[39mreshape3f(Y, Y\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], nO, nP)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ],
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test['title'] = test['title'].str.lower()\n",
    "test['content'] = test['content'].str.lower()\n",
    "\n",
    "test['title_processed'] = preprocess_texts(test['title'].tolist())\n",
    "test['content_processed'] = preprocess_texts(test['content'].tolist())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:13:57.598150Z",
     "iopub.status.idle": "2024-03-30T16:13:57.598639Z",
     "shell.execute_reply.started": "2024-03-30T16:13:57.598430Z",
     "shell.execute_reply": "2024-03-30T16:13:57.598449Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train['content_processed']=train['content_processed']+train['title_processed']\n",
    "test['content_processed']=test['content_processed']+test['title_processed']"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:13:57.600092Z",
     "iopub.status.idle": "2024-03-30T16:13:57.600510Z",
     "shell.execute_reply.started": "2024-03-30T16:13:57.600310Z",
     "shell.execute_reply": "2024-03-30T16:13:57.600327Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Prepare Documents for Word2Vec\n",
    "documents = [text.split() for text in pd.concat([train['content_processed'], test['content_processed']])]\n",
    "\n",
    "# Train Word2Vec on the entire dataset\n",
    "word2vec_model = Word2Vec(sentences=documents, vector_size=100, window=5, min_count=1, workers=4)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T13:46:12.671574Z",
     "iopub.execute_input": "2024-03-30T13:46:12.671914Z",
     "iopub.status.idle": "2024-03-30T13:49:19.788568Z",
     "shell.execute_reply.started": "2024-03-30T13:46:12.671885Z",
     "shell.execute_reply": "2024-03-30T13:49:19.786885Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Document Vector Function\n",
    "def document_vector(word2vec_model, doc):\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "    if not doc:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "    return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "\n",
    "# Apply the Function to Create Document Vectors\n",
    "train_vectors = np.array([document_vector(word2vec_model, doc.split()) for doc in train['content_processed']])\n",
    "test_vectors = np.array([document_vector(word2vec_model, doc.split()) for doc in test['content_processed']])\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T13:49:19.790177Z",
     "iopub.execute_input": "2024-03-30T13:49:19.791440Z",
     "iopub.status.idle": "2024-03-30T13:50:39.062123Z",
     "shell.execute_reply.started": "2024-03-30T13:49:19.791405Z",
     "shell.execute_reply": "2024-03-30T13:50:39.060731Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming train_vectors and test_vectors are already defined\n",
    "\n",
    "# Save train_vectors to CSV\n",
    "np.savetxt('train_vectors.csv', train_vectors, delimiter=',')\n",
    "\n",
    "# Save test_vectors to CSV\n",
    "np.savetxt('test_vectors.csv', test_vectors, delimiter=',')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T13:50:39.065627Z",
     "iopub.execute_input": "2024-03-30T13:50:39.066449Z",
     "iopub.status.idle": "2024-03-30T13:50:51.354422Z",
     "shell.execute_reply.started": "2024-03-30T13:50:39.066405Z",
     "shell.execute_reply": "2024-03-30T13:50:51.352906Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load train vectors from CSV\n",
    "\n",
    "train_vectors = np.genfromtxt('/kaggle/input/vectors/train_vectors.csv', delimiter=',')\n",
    "\n",
    "# Load test vectors from CSV\n",
    "test_vectors = np.genfromtxt('/kaggle/input/vectors/test_vectors.csv', delimiter=',')\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:19:01.584573Z",
     "iopub.execute_input": "2024-03-30T16:19:01.585332Z",
     "iopub.status.idle": "2024-03-30T16:19:20.982585Z",
     "shell.execute_reply.started": "2024-03-30T16:19:01.585301Z",
     "shell.execute_reply": "2024-03-30T16:19:20.981452Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Naive Bayes**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Train-Test Split (For Evaluating Model Performance)\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "labels = train['class'].astype(int).values\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_vectors, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and Train the Classifier\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the Validation Set and Evaluate\n",
    "y_val_pred = clf.predict(X_val)\n",
    "print(f\"Validation Accuracy: {accuracy_score(y_val, y_val_pred)}\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**SVM**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the SVC classifier\n",
    "clf = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(train_vectors, labels)  # Assuming train_vectors and labels are defined\n",
    "\n",
    "# Predict on the Test Set\n",
    "test_predictions = clf.predict(test_vectors)\n",
    "\n",
    "# Ensure test_predictions are in the format of integers 0 and 1\n",
    "test_predictions_int = [int(pred) for pred in test_predictions]\n",
    "\n",
    "# Create a DataFrame with IDs and predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test['id'],  # Replace 'id' with the actual name of your ID column if it's different\n",
    "    'class': test_predictions_int\n",
    "})\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "submission_df.to_csv('submission_svm.csv', index=False)\n",
    "\n",
    "print(\"Submission CSV file for SVM predictions has been created.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CNN**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "X_train = np.expand_dims(train_vectors, axis=2)\n",
    "X_test = np.expand_dims(test_vectors, axis=2)\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=256, kernel_size=7, activation='relu', input_shape=(100, 1)))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "X = train_vectors  # Feature vectors\n",
    "y = train['labels'].values\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "history = model.fit(X_train, y_train, epochs=5, validation_split=0.1, batch_size=32)\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Assuming you have predictions for your validation set\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "\n",
    "balanced_acc = balanced_accuracy_score(y_val, y_pred_binary)\n",
    "print(\"Balanced Accuracy:\", balanced_acc)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T14:28:24.591343Z",
     "iopub.execute_input": "2024-03-30T14:28:24.592429Z",
     "iopub.status.idle": "2024-03-30T14:29:53.515458Z",
     "shell.execute_reply.started": "2024-03-30T14:28:24.592353Z",
     "shell.execute_reply": "2024-03-30T14:29:53.513856Z"
    },
    "trusted": true
   },
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": "(70575, 100) (70575,)\nEpoch 1/5\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "\u001B[1m1588/1588\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 9ms/step - accuracy: 0.8749 - loss: 0.2967 - val_accuracy: 0.9245 - val_loss: 0.1940\nEpoch 2/5\n\u001B[1m1588/1588\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 9ms/step - accuracy: 0.9226 - loss: 0.1988 - val_accuracy: 0.9283 - val_loss: 0.1904\nEpoch 3/5\n\u001B[1m1588/1588\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m20s\u001B[0m 9ms/step - accuracy: 0.9310 - loss: 0.1778 - val_accuracy: 0.9143 - val_loss: 0.2178\nEpoch 4/5\n\u001B[1m1588/1588\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m15s\u001B[0m 9ms/step - accuracy: 0.9340 - loss: 0.1737 - val_accuracy: 0.9299 - val_loss: 0.1863\nEpoch 5/5\n\u001B[1m1588/1588\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m16s\u001B[0m 10ms/step - accuracy: 0.9347 - loss: 0.1667 - val_accuracy: 0.9394 - val_loss: 0.1645\n\u001B[1m442/442\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 4ms/step\nBalanced Accuracy: 0.9349836666230912\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "history = model.fit(X,y, epochs=5, validation_split=0.1, batch_size=32)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T14:31:15.876817Z",
     "iopub.execute_input": "2024-03-30T14:31:15.877249Z",
     "iopub.status.idle": "2024-03-30T14:32:46.237137Z",
     "shell.execute_reply.started": "2024-03-30T14:31:15.877216Z",
     "shell.execute_reply": "2024-03-30T14:32:46.235671Z"
    },
    "trusted": true
   },
   "execution_count": 55,
   "outputs": [
    {
     "name": "stdout",
     "text": "Epoch 1/5\n\u001B[1m1985/1985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 9ms/step - accuracy: 0.9348 - loss: 0.1714 - val_accuracy: 0.9442 - val_loss: 0.1499\nEpoch 2/5\n\u001B[1m1985/1985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 9ms/step - accuracy: 0.9348 - loss: 0.1685 - val_accuracy: 0.9433 - val_loss: 0.1454\nEpoch 3/5\n\u001B[1m1985/1985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 9ms/step - accuracy: 0.9372 - loss: 0.1630 - val_accuracy: 0.9432 - val_loss: 0.1445\nEpoch 4/5\n\u001B[1m1985/1985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 9ms/step - accuracy: 0.9392 - loss: 0.1587 - val_accuracy: 0.9436 - val_loss: 0.1462\nEpoch 5/5\n\u001B[1m1985/1985\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m18s\u001B[0m 9ms/step - accuracy: 0.9389 - loss: 0.1580 - val_accuracy: 0.9432 - val_loss: 0.1474\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred = model.predict(test_vectors)\n",
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T15:05:59.593344Z",
     "iopub.execute_input": "2024-03-30T15:05:59.593911Z",
     "iopub.status.idle": "2024-03-30T15:06:03.837275Z",
     "shell.execute_reply.started": "2024-03-30T15:05:59.593870Z",
     "shell.execute_reply": "2024-03-30T15:06:03.836064Z"
    },
    "trusted": true
   },
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "text": "\u001B[1m1146/1146\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m4s\u001B[0m 3ms/step\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import csv\n",
    "submission_df = pd.DataFrame({'class': y_pred_binary.flatten()})\n",
    "print(submission_df)\n",
    "submission_df.to_csv('predictionFolly.csv', index=True)\n",
    "print(\"Submission CSV file for SVM predictions has been created.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T15:06:16.715158Z",
     "iopub.execute_input": "2024-03-30T15:06:16.716387Z",
     "iopub.status.idle": "2024-03-30T15:06:16.776096Z",
     "shell.execute_reply.started": "2024-03-30T15:06:16.716331Z",
     "shell.execute_reply": "2024-03-30T15:06:16.774681Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "trusted": true
   },
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "text": "       class\n0          0\n1          1\n2          1\n3          1\n4          0\n...      ...\n36664      0\n36665      0\n36666      1\n36667      1\n36668      0\n\n[36669 rows x 1 columns]\nSubmission CSV file for SVM predictions has been created.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Random Forest **"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_vectors, train['labels'], test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "predictions = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Additional evaluation metrics\n",
    "print(classification_report(y_test, predictions))\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T15:10:28.296709Z",
     "iopub.execute_input": "2024-03-30T15:10:28.297613Z",
     "iopub.status.idle": "2024-03-30T15:12:15.753322Z",
     "shell.execute_reply.started": "2024-03-30T15:10:28.297557Z",
     "shell.execute_reply": "2024-03-30T15:12:15.751933Z"
    },
    "trusted": true
   },
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "text": "Accuracy: 0.9540913921360255\n              precision    recall  f1-score   support\n\n           0       0.94      0.93      0.94      5053\n           1       0.96      0.96      0.96      9062\n\n    accuracy                           0.95     14115\n   macro avg       0.95      0.95      0.95     14115\nweighted avg       0.95      0.95      0.95     14115\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "rf_classifier.fit(X,y)\n",
    "predictions = rf_classifier.predict(test_vectors)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T15:13:40.632179Z",
     "iopub.execute_input": "2024-03-30T15:13:40.632605Z",
     "iopub.status.idle": "2024-03-30T15:16:07.971652Z",
     "shell.execute_reply.started": "2024-03-30T15:13:40.632575Z",
     "shell.execute_reply": "2024-03-30T15:16:07.970383Z"
    },
    "trusted": true
   },
   "execution_count": 81,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "y_pred_binary = (y_pred > 0.5).astype(int)  # Convert probabilities to binary predictions\n",
    "import csv\n",
    "submission_df = pd.DataFrame({'class': predictions.flatten()})\n",
    "print(submission_df)\n",
    "submission_df.to_csv('predictionFolly.csv', index=True)\n",
    "print(\"Submission CSV file for SVM predictions has been created.\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T15:17:54.408904Z",
     "iopub.execute_input": "2024-03-30T15:17:54.409909Z",
     "iopub.status.idle": "2024-03-30T15:17:54.467463Z",
     "shell.execute_reply.started": "2024-03-30T15:17:54.409861Z",
     "shell.execute_reply": "2024-03-30T15:17:54.466218Z"
    },
    "trusted": true
   },
   "execution_count": 83,
   "outputs": [
    {
     "name": "stdout",
     "text": "       class\n0          0\n1          1\n2          0\n3          1\n4          0\n...      ...\n36664      0\n36665      0\n36666      1\n36667      1\n36668      0\n\n[36669 rows x 1 columns]\nSubmission CSV file for SVM predictions has been created.\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Transformers**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install transformers\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T15:24:17.162034Z",
     "iopub.execute_input": "2024-03-30T15:24:17.163178Z",
     "iopub.status.idle": "2024-03-30T15:24:31.786376Z",
     "shell.execute_reply.started": "2024-03-30T15:24:17.163136Z",
     "shell.execute_reply": "2024-03-30T15:24:31.784754Z"
    },
    "trusted": true
   },
   "execution_count": 84,
   "outputs": [
    {
     "name": "stderr",
     "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
     "output_type": "stream"
    },
    {
     "name": "stdout",
     "text": "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.21.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.3.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.2.2)\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-cased')\n",
    "def bert_encode(texts, tokenizer, model, max_length=512):\n",
    "    all_input_ids = []\n",
    "    all_attention_masks = []\n",
    "    all_token_type_ids = []\n",
    "    \n",
    "    for text in texts:\n",
    "        encoded_text = tokenizer.encode_plus(text, \n",
    "                                             max_length=max_length, \n",
    "                                             pad_to_max_length=True, \n",
    "                                             add_special_tokens=True, \n",
    "                                             return_attention_mask=True, \n",
    "                                             return_token_type_ids=True, \n",
    "                                             truncation=True)\n",
    "        \n",
    "        all_input_ids.append(encoded_text['input_ids'])\n",
    "        all_attention_masks.append(encoded_text['attention_mask'])\n",
    "        all_token_type_ids.append(encoded_text['token_type_ids'])\n",
    "    \n",
    "    all_input_ids = np.array(all_input_ids)\n",
    "    all_attention_masks = np.array(all_attention_masks)\n",
    "    all_token_type_ids = np.array(all_token_type_ids)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=torch.tensor(all_input_ids), \n",
    "                        attention_mask=torch.tensor(all_attention_masks), \n",
    "                        token_type_ids=torch.tensor(all_token_type_ids))\n",
    "    \n",
    "    return outputs.last_hidden_state[:, 0, :].numpy()\n",
    "\n",
    "\n",
    "\n",
    "train_embeddings = bert_encode(train['content_processed'].tolist(), tokenizer, model)\n",
    "test_embeddings = bert_encode(test['content_processed'].tolist(), tokenizer, model)\n"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-30T16:19:49.929955Z",
     "iopub.execute_input": "2024-03-30T16:19:49.930339Z",
     "iopub.status.idle": "2024-03-30T16:20:00.961742Z",
     "shell.execute_reply.started": "2024-03-30T16:19:49.930310Z",
     "shell.execute_reply": "2024-03-30T16:20:00.960178Z"
    },
    "trusted": true
   },
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ecc721ed310b485cba2f99e9b66c682a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6deb5591c8d5494dbc034633ba0f38ec"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/1.96M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ee44531c32ab423584035c7599644e59"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/625 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aa78c80229a64c918edb8de976818a1c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "model.safetensors:   0%|          | 0.00/714M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "056e462d6a81484f886aa48910e766ad"
      }
     },
     "metadata": {}
    },
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3804\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3805\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3806\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32mindex.pyx:167\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mindex.pyx:196\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'content_processed'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 37\u001B[0m\n\u001B[1;32m     29\u001B[0m         outputs \u001B[38;5;241m=\u001B[39m model(input_ids\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor(all_input_ids), \n\u001B[1;32m     30\u001B[0m                         attention_mask\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor(all_attention_masks), \n\u001B[1;32m     31\u001B[0m                         token_type_ids\u001B[38;5;241m=\u001B[39mtorch\u001B[38;5;241m.\u001B[39mtensor(all_token_type_ids))\n\u001B[1;32m     33\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m outputs\u001B[38;5;241m.\u001B[39mlast_hidden_state[:, \u001B[38;5;241m0\u001B[39m, :]\u001B[38;5;241m.\u001B[39mnumpy()\n\u001B[0;32m---> 37\u001B[0m train_embeddings \u001B[38;5;241m=\u001B[39m bert_encode(\u001B[43mtrain\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mcontent_processed\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mtolist(), tokenizer, model)\n\u001B[1;32m     38\u001B[0m test_embeddings \u001B[38;5;241m=\u001B[39m bert_encode(test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcontent_processed\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mtolist(), tokenizer, model)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/frame.py:4090\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   4088\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   4089\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 4090\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   4091\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   4092\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3807\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[1;32m   3808\u001B[0m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc\u001B[38;5;241m.\u001B[39mIterable)\n\u001B[1;32m   3809\u001B[0m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[1;32m   3810\u001B[0m     ):\n\u001B[1;32m   3811\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[0;32m-> 3812\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3813\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3814\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3815\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3816\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3817\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'content_processed'"
     ],
     "ename": "KeyError",
     "evalue": "'content_processed'",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Example: Train a classifier (e.g., RandomForest)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "clf.fit(train_embeddings, train['labels'])\n",
    "\n",
    "# Predictions\n",
    "predictions = clf.predict(test_embeddings)\n",
    "\n",
    "# Evaluation\n",
    "# Make sure to have your test labels to evaluate predictions\n"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ]
}
